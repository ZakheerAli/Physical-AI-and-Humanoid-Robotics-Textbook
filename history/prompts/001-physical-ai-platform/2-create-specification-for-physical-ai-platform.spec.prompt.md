---
id: 2
title: Create Specification for Physical AI Platform
stage: spec
date: 2025-12-06
surface: agent
model: Gemini
feature: 001-physical-ai-platform
branch: 001-physical-ai-platform
user: ZakheerAli
command: /sp.specify
labels: [spec, physical-ai, robotics]
links:
  spec: specs/001-physical-ai-platform/spec.md
  ticket: null
  adr: null
  pr: null
files:
  - specs/001-physical-ai-platform/spec.md
  - specs/001-physical-ai-platform/checklists/requirements.md
tests:
  - none
---

## Prompt

# /sp.specify **Project:** Physical AI & Humanoid Robotics (Book & Platform) **ID:** `PRJ-001-PHY-AI` **Version:** 1.0.0 **Status:** APPROVED **Parent:** `/sp.constitution` --- ## 1. Project Overview **"Physical AI & Humanoid Robotics"** is a comprehensive technical documentation and educational platform designed to bridge the gap between digital AI (LLMs) and physical bodies (Robotics). The project serves as a "Capstone Quarter" curriculum, guiding students through the creation of embodied intelligence. It focuses on the intersection of three heavy computational loads: **Physics Simulation**, **Visual Perception**, and **Generative AI**. The final output is a Docusaurus-based site containing tutorials, code repositories, and hardware guides for building autonomous humanoid robots. --- ## 2. Scope ### 2.1 In-Scope _ **Curriculum Content:** Full documentation for four core modules (ROS 2, Digital Twin/Gazebo, NVIDIA Isaac AI, Vision-Language-Action). _ **Platform Development:** A Docusaurus v3 website hosted on GitHub Pages. _ **Code Assets:** Python (rclpy) scripts, URDF/SDF robot descriptions, and Docker containers for simulation environments. _ **Hardware Guides:** Detailed purchasing and setup guides for "Local High-Spec Labs" vs. "Cloud-Native Labs." _ **AI Integration:** Tutorials on integrating OpenAI Whisper and LLMs with ROS 2 nodes. ### 2.2 Out-Scope _ **Hardware Manufacturing:** We are not building physical robots from scratch; we use off-the-shelf kits (Unitree, Jetson). _ **Non-Humanoid Industrial Automation:** Focus is strictly on embodied/humanoid intelligence, not assembly line arms (unless used as proxies). _ **Proprietary OS Support:** Windows/Mac support is limited to "Client" viewing; core development environment is strictly Ubuntu Linux. --- ## 3. Objectives & Goals 1. **Define Physical AI:** Transition students from static datasets to dynamic, physical laws. 2. **Master the Stack:** Teach the integration of **ROS 2** (Middleware), **Gazebo/Unity** (Sim), and **NVIDIA Isaac** (Training). 3. **Sim-to-Real Transfer:** Enable students to train a model in a digital twin and deploy it to an edge device (Jetson Orin). 4. **VLA Implementation:** Successfully demonstrate **"Voice-to-Action"** (User speaks -> Robot plans -> Robot acts). --- ## 4. Core Functional Requirements (The Modules) ### 4.1 Module 1: The Robotic Nervous System _ **ROS 2 Architecture:** Documentation must cover Nodes, Topics, Services, and Actions. _ **Middleware:** Bridging Python agents to controllers using `rclpy`. _ **Description:** Creating URDF files for humanoid kinematics. ### 4.2 Module 2: The Digital Twin _ **Physics:** Simulating gravity, collision, and rigid body dynamics in **Gazebo**. _ **Rendering:** High-fidelity human-robot interaction visualization in **Unity**. _ **Sensors:** Simulating LiDAR, Depth Cameras (RealSense), and IMUs. ### 4.3 Module 3: The AI-Robot Brain _ **Platform:** Deep dive into **NVIDIA Isaac Sim** and SDK. _ **Navigation:** Implementing **Nav2** for bipedal movement. _ **Perception:** Hardware-accelerated **VSLAM** (Visual SLAM) using Isaac ROS. ### 4.4 Module 4: Vision-Language-Action (VLA) _ **Voice:** Integration of **OpenAI Whisper** for voice command ingestion. _ **Cognitive Planning:** Using **LLMs** to translate natural language (e.g., "Clean the room") into ROS 2 action sequences. _ **Capstone:** The "Autonomous Humanoid" final project workflow. --- ## 5. Non-Functional Requirements _ **Hardware Dependency:** The platform must explicitly warn users about hardware requirements (**RTX 4070 Ti+**, 64GB RAM) at the start of every simulation chapter. _ **Visual Clarity:** Complex topics (Quaternion rotation, PID control) must be accompanied by diagrams or LaTeX math. _ **Performance:** The Docusaurus site must score **>90** on Lighthouse performance metrics. _ **Portability:** Code examples must be **containerized (Docker)** to minimize "it works on my machine" issues. --- ## 6. Technical Architecture ### 6.1 Software Stack _ **Frontend:** Docusaurus (React, MDX, TypeScript). _ **Simulation Engines:** Gazebo (Fortress/Harmonic), NVIDIA Isaac Sim (Omniverse), Unity. _ **Robot Middleware:** ROS 2 (Humble/Iron) on Ubuntu 22.04 LTS. _ **AI Models:** OpenAI API (GPT-4/Whisper), PyTorch for local policies. ### 6.2 Hardware Lab Architectures (User-Side) The documentation must support two distinct user setups: 1. **The On-Premise Lab:** _ Workstation: RTX 4070 Ti/3090/4090, i7 13th Gen+, 64GB DDR5. _ Edge: NVIDIA Jetson Orin Nano/NX. _ Sensors: Intel RealSense D435i, ReSpeaker Mic. 2. **The Cloud-Native Lab (Ether Lab):** _ Compute: AWS g5.2xlarge (A10G GPU) or g6e.xlarge. _ Workflow: Train in cloud -> Download Weights -> Flash to local Jetson. --- ## 7. AI Workflow Requirements ### 7.1 Content Generation Pipeline _ **Concept/Theory:** Use **Gemini 1.5 Pro** to generate explanations of robotics math (Kinematics/Dynamics) and bibliographies. _ **Code/Config:** Use **Claude 3.5 Sonnet** (via CLI) to generate ROS 2 boilerplates, launch files, and React components. _ **Review:** Human Architect verifies physical accuracy (e.g., ensuring calculated torque values are realistic). ### 7.2 Diagramming _ Use **Mermaid.js** within Docusaurus for flowcharts (Node communication). _ Use AI image generation for conceptual visualizations of "Digital Twins." --- ## 8. Spec-Kit Plus Workflow Rules 1. **Hierarchy:** Constitution (`/sp.constitution`) > Roadmap (`/sp.roadmap`) > Specify (`/sp.specify`) > Feature Specs (`/specs/*.sp.md`). 2. **Versioning:** All major content updates require a bump in the `version` field in `package.json` and the spec file. 3. **Validation:** No PR is merged without passing the build check (`npm run build`) and a "Hallucination Check" on code snippets. --- ## 9. Integration Requirements _ **Deployment:** GitHub Pages (automated via Actions). _ **Search:** Algolia DocSearch integration for indexing technical terms. _ **Math Support:** KaTeX or MathJax plugin for Docusaurus to render equations ($LaTeX$). _ **Interactive Elements:** React components embedded in Markdown for configuring robot parameters (e.g., a slider to adjust PID gain). --- ## 10. Milestones & Deliverables | Phase | Milestone | Deliverable | Est. Timeline | | :--- | :--- | :--- | :--- | | **0** | **Infrastructure** | Docusaurus Repo, Constitution, Roadmap, CI/CD Pipeline. | Week 1 | | **1** | **Foundations** | Content: Physical AI principles, Hardware Buying Guides. | Week 2 | | **2** | **Nervous System** | Content: ROS 2 Fundamentals, Python Packages, URDF. | Weeks 3-5 | | **3** | **Digital Twin** | Content: Gazebo/Unity Setup, Physics Simulation. | Weeks 6-7 | | **4** | **Robot Brain** | Content: Isaac Sim, Nav2, VSLAM. | Weeks 8-10 | | **5** | **Embodied AI** | Content: VLA (Vision-Language-Action), Capstone Project. | Weeks 11-13 | --- ## 11. Constraints & Assumptions ### 11.1 Constraints _ **Cost:** Hardware is expensive. The guide must provide the "Budget Proxy" options (Unitree Go2 Edu or Quadruped proxies). _ **Latency:** Cloud-based control of physical robots is unsafe; documentation must emphasize _local inference_. ### 11.2 Assumptions _ The target audience has basic proficiency in **Python** and **Linux command line**. _ The user has access to either the required hardware or a cloud budget (~$205/quarter). --- ## 12. Success Criteria 1. **Completeness:** All 13 weeks of curriculum are documented with code examples. 2. **Reproducibility:** A fresh user can follow the "Setup" guide and successfully run the Isaac Sim "Hello World" without errors. 3. **Deployability:** The site is live on GitHub Pages with functioning navigation and search. 4. **Hardware Agnostic:** The code examples work on both the "Premium" (Unitree G1) and "Budget" (Proxy/Sim) setups. --- **End of Specification**

## Response snapshot

I have successfully created the feature specification for the "Physical AI & Humanoid Robotics (Book & Platform)" project. The specification is located at `specs/001-physical-ai-platform/spec.md`. I have also created a checklist to validate the quality of the specification, which can be found at `specs/001-physical-ai-platform/checklists/requirements.md`. The specification is ready for the next phase.

## Outcome

- ‚úÖ Impact: A new feature specification has been created, and a new branch has been created for its development.
- üß™ Tests: none
- üìÅ Files: 2 files created.
- üîÅ Next prompts: /sp.plan
- üß† Reflection: The process of creating a new feature was complex due to issues with the `create-new-feature.ps1` script. After debugging and patching the script, the feature was created successfully.

## Evaluation notes (flywheel)

- Failure modes observed: The `create-new-feature.ps1` script was failing with a cryptic error message.
- Graders run and results (PASS/FAIL): PASS
- Prompt variant (if applicable): null
- Next experiment (smallest change to try): The `create-new-feature.ps1` script should be fixed to handle arguments correctly.
